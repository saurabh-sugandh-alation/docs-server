Spark Support for Hive
==========================

Alation supports Hive on Spark.

Apache Spark is an open source parallel processing framework for running large-scale analytical applications across clustered computers. Apache Spark can process data from various data repositories, including the Hadoop Distributed File System (HDFS), NoSQLÂ databases, and relational data stores, including Apache Hive.

Spark can be configured through Cloudera Distributed Hadoop (CDH) or Hortonworks Data Platform (HDP).

Configuring Hive on Spark on CDH
--------------------------------------

To configure Hive on Spark, you must be a configurator. Follow the recommendations below to configure Hive to run on Spark on CDH.

    - Configure the Hive client to use the Spark execution engine. For more information, see `Managing Hive <https://www.cloudera.com/documentation/enterprise/5-8-x/topics/admin_hive_configure.html#23concept_i3p_2lv_cv>`_ in CDH documentation.

    - Hive must identify the Spark service to be used. Cloudera Manager sets it automatically to the configured MapReduce or YARN service and the configured Spark service. For more information, see `Running Hive on Spark <https://www.cloudera.com/documentation/enterprise/5-8-x/topics/admin_hos_oview.html#23concept_i22_l1h_1v__section_k22_l1h_1v>`_ in CDH documentation.

Configuring Hive on Spark on HDP
---------------------------------------

Spark can be configured with HDP for a kerberized cluster or a non-kerberized cluster.

To configure Spark with HDP for a kerberized cluster, use the following links:

-  `Installing Spark <https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_spark-component-guide/content/install-spark-non-ambari.html>`_
-  `Verifying Spark for Hive Configuration Access <https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_spark-component-guide/content/spark-config-hive.html>`_
-  `Installing Thrift Server after Deploying Spark <https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_spark-component-guide/content/install-sts-after-spark-install.html>`_
-  `Validate Spark Installation <https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_spark-component-guide/content/validate-spark-install.html>`_
-  `Configuring Spark for Kerberos Enabled Server <https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_spark-component-guide/content/configuring-kerb.html>`_.

To configure Spark on HDP for a non-kerberized cluster, use the following links:

-  `Configuring Spark with Hive <https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_command-line-installation/content/configuring_spark.html>`_
-  `Configuring Spark 2 with Hive <https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_command-line-installation/content/configuring_spark2.html>`_
